import os
import duckdb
import time
import pandas as pd
from playwright.sync_api import sync_playwright

# ì„¤ì •
MD_TOKEN = os.getenv("MOTHERDUCK_TOKEN")
API_KEY = os.getenv("DART_API_KEY")
DB_PATH = "md:"
APP_URL = "https://search-dart.streamlit.app/~/+/"
DEFAULT_PERIOD = "202509" # ê¸°ë³¸ ê¸°ì¤€ì—°ì›”
BATCH_SIZE = 10 # í•œ ë²ˆì— ì²˜ë¦¬í•  íšŒì‚¬ ìˆ˜

import requests
import zipfile
import io
import xml.etree.ElementTree as ET

def sync_corp_codes():
    """DART APIì—ì„œ íšŒì‚¬ ì½”ë“œë¥¼ ê°€ì ¸ì™€ DBì— ì €ì¥í•©ë‹ˆë‹¤."""
    if not API_KEY:
        print("DART_API_KEY is not set. Skipping sync.")
        return False
    
    print("Syncing corp codes from DART API...")
    url = "https://opendart.fss.or.kr/api/corpCode.xml"
    params = {'crtfc_key': API_KEY}
    
    try:
        response = requests.get(url, params=params)
        if response.status_code == 200:
            with zipfile.ZipFile(io.BytesIO(response.content)) as zip_file:
                xml_filename = zip_file.namelist()[0]
                with zip_file.open(xml_filename) as f:
                    tree = ET.parse(f)
                    root = tree.getroot()
                    data_list = []
                    for corp in root.findall('.//list'):
                        code = corp.findtext('corp_code', '').strip()
                        name = corp.findtext('corp_name', '').strip()
                        stock = corp.findtext('stock_code', '').strip()
                        # ì£¼ì‹ ì½”ë“œê°€ ìˆëŠ”(ìƒì¥ì‚¬) ê²½ìš°ì—ë§Œ ì¶”ê°€
                        if code and name and stock:
                            data_list.append((code, name, stock))
            
            if data_list:
                print(f"[Database] Preparing to insert {len(data_list)} records...", flush=True)
                df = pd.DataFrame(data_list, columns=['corp_code', 'corp_name', 'stock_code'])
                
                conn = duckdb.connect(DB_PATH, config={'motherduck_token': MD_TOKEN})
                conn.execute("CREATE DATABASE IF NOT EXISTS dart_financials")
                conn.execute("USE dart_financials")
                conn.execute("""
                    CREATE TABLE IF NOT EXISTS corp_codes (
                        corp_code VARCHAR PRIMARY KEY,
                        corp_name VARCHAR,
                        stock_code VARCHAR,
                        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                    )
                """)
                # [ìˆ˜ì •] ìŠ¤í‚¤ë§ˆ ë³€ê²½ ì‹œ ì»¬ëŸ¼ ì¶”ê°€ë¥¼ ìœ„í•´ ì²˜ë¦¬
                try:
                    conn.execute("ALTER TABLE corp_codes ADD COLUMN IF NOT EXISTS stock_code VARCHAR")
                except:
                    pass

                print("[Database] Executing bulk insert (INSERT OR REPLACE)...", flush=True)
                conn.execute("INSERT OR REPLACE INTO corp_codes (corp_code, corp_name, stock_code) SELECT corp_code, corp_name, stock_code FROM df")
                conn.close()
                print(f"[Database] Successfully synced {len(data_list)} corp codes.", flush=True)
                return True
        return False
    except Exception as e:
        print(f"Failed to sync corp codes: {e}")
        return False

def get_unprocessed_companies():
    """ì•„ì§ ì²˜ë¦¬ë˜ì§€ ì•Šì€ íšŒì‚¬ ëª©ë¡ì„ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    try:
        print(f"[Database] Connecting to MotherDuck (Path: {DB_PATH})...", flush=True)
        conn = duckdb.connect(DB_PATH, config={'motherduck_token': MD_TOKEN})
        print("[Database] Connected. Initializing tables...", flush=True)
        conn.execute("CREATE DATABASE IF NOT EXISTS dart_financials")
        conn.execute("USE dart_financials")
        
        # í…Œì´ë¸” ì¡´ì¬ í™•ì¸ ë° ìƒì„±
        conn.execute("""
            CREATE TABLE IF NOT EXISTS corp_codes (
                corp_code VARCHAR PRIMARY KEY,
                corp_name VARCHAR,
                stock_code VARCHAR,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """)
        # [ìˆ˜ì •] ìŠ¤í‚¤ë§ˆ ë³€ê²½ ì‹œ ì»¬ëŸ¼ ì¶”ê°€ë¥¼ ìœ„í•´ ì²˜ë¦¬
        try:
            conn.execute("ALTER TABLE corp_codes ADD COLUMN IF NOT EXISTS stock_code VARCHAR")
        except:
            pass
        conn.execute("""
            CREATE TABLE IF NOT EXISTS processing_status (
                corp_code VARCHAR,
                corp_name VARCHAR,
                last_base_period VARCHAR,
                status VARCHAR DEFAULT 'SUCCESS',
                processed_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                PRIMARY KEY (corp_code)
            )
        """)
        # [ìˆ˜ì •] ìŠ¤í‚¤ë§ˆ ë³€ê²½ ì‹œ ì»¬ëŸ¼ ì¶”ê°€ë¥¼ ìœ„í•´ ì²˜ë¦¬
        try:
            conn.execute("ALTER TABLE processing_status ADD COLUMN IF NOT EXISTS status VARCHAR DEFAULT 'SUCCESS'")
        except:
            pass
        
        # ë°ì´í„°ê°€ ìˆëŠ”ì§€ í™•ì¸
        count = conn.execute("SELECT count(*) FROM corp_codes").fetchone()[0]
        print(f"[Database] Current corp_codes count: {count}", flush=True)
        if count == 0:
            conn.close()
            if sync_corp_codes():
                return get_unprocessed_companies() # ì¬ì‹œë„
            return []

        print("[Database] Fetching unprocessed companies...", flush=True)
        query = """
            SELECT c.corp_name, c.corp_code 
            FROM corp_codes c
            LEFT JOIN processing_status p ON c.corp_code = p.corp_code
            WHERE p.corp_code IS NULL
            ORDER BY c.corp_code ASC
            LIMIT ?
        """
        df = conn.execute(query, [BATCH_SIZE]).df()
        conn.close()
        return df.to_dict('records')
    except Exception as e:
        print(f"[Database Error] {e}", flush=True)
        return []

def update_status_to_not_found(corp_code, corp_name):
    """ì‹¤íŒ¨í•œ ê²½ìš°(ì„±ê³µ ì™¸) ìƒíƒœë¥¼ NOT_FOUNDë¡œ ê¸°ë¡í•©ë‹ˆë‹¤."""
    try:
        conn = duckdb.connect(DB_PATH, config={'motherduck_token': MD_TOKEN})
        conn.execute("USE dart_financials")
        conn.execute("""
            INSERT OR REPLACE INTO processing_status (corp_code, corp_name, last_base_period, status, processed_at)
            VALUES (?, ?, ?, 'NOT_FOUND', CURRENT_TIMESTAMP)
        """, [corp_code, corp_name, DEFAULT_PERIOD])
        conn.close()
        print(f"  - [Fallback] Status recorded as NOT_FOUND for {corp_name}", flush=True)
    except Exception as e:
        print(f"  - [Error] Failed to record fallback status: {e}", flush=True)

def run_automation():
    print("--- Starting Automation Script ---", flush=True)
    companies = get_unprocessed_companies()
    if not companies:
        print("[Status] No unprocessed companies found. Everything is up to date.", flush=True)
        return

    print(f"[Status] Found {len(companies)} companies to process.", flush=True)

    with sync_playwright() as p:
        print("[Playwright] Launching browser...", flush=True)
        browser = p.chromium.launch(headless=True)
        context = browser.new_context(viewport={'width': 1280, 'height': 800})
        page = context.new_page()

        for i, company in enumerate(companies):
            name = company['corp_name']
            code = company['corp_code']
            print(f"\n[{i+1}/{len(companies)}] Processing: {name} ({code})", flush=True)

            try:
                print(f"  - Navigating to {APP_URL}...", flush=True)
                page.goto(APP_URL, wait_until="networkidle", timeout=30000)
                
                print("  - Waiting for Streamlit UI to load (30s timeout)...", flush=True)
                input_selector = 'input[aria-label="íšŒì‚¬ëª…"]'
                page.locator(input_selector).wait_for(state="visible", timeout=30000)
                
                print(f"  - Filling company name: {name}", flush=True)
                page.get_by_label("íšŒì‚¬ëª…").fill(name)
                page.get_by_label("íšŒì‚¬ëª…").press("Enter")
                time.sleep(0.5) # Streamlit ìƒíƒœ ë™ê¸°í™” ëŒ€ê¸°
                
                print(f"  - Filling period: {DEFAULT_PERIOD}", flush=True)
                page.get_by_label("ê¸°ì¤€ ì—°ì›” (YYYYMM)").fill(DEFAULT_PERIOD)
                page.get_by_label("ê¸°ì¤€ ì—°ì›” (YYYYMM)").press("Enter")
                time.sleep(0.5) # Streamlit ìƒíƒœ ë™ê¸°í™” ëŒ€ê¸°
                
                print("  - Clicking 'ì¡°íšŒí•˜ê¸°' button...", flush=True)
                try:
                    page.get_by_role("button", name="ì¡°íšŒí•˜ê¸°").click(timeout=3000)
                except:
                    pass
                
                print("  - Waiting for data collection results (120s timeout)...", flush=True)
                try:
                    # ì™„ê²°ì„± ìˆëŠ” ì„±ê³µ/ì‹¤íŒ¨ íŒë‹¨ì„ ìœ„í•´ ì—¬ëŸ¬ ì§€í‘œë¥¼ í•œêº¼ë²ˆì— ëŒ€ê¸°
                    success_indicators = [
                        page.locator('summary:has-text("ì¡°íšŒ ì™„ë£Œ")'),
                        page.locator('p:has-text("ì¡°íšŒ ì™„ë£Œ")'),
                        page.locator('h3:has-text("ğŸ¢")'),
                        page.locator('h1:has-text("ğŸ¢")'), # ê°€ë” H1ìœ¼ë¡œ ë‚˜ì˜¬ ìˆ˜ ìˆìŒ
                        page.locator('h3:has-text("ì¬ë¬´ ì¶”ì´")'),
                        page.locator('[data-testid="stMetricValue"]') # ì§€í‘œ ë°•ìŠ¤
                    ]
                    
                    error_indicators = [
                        page.locator('summary:has-text("íšŒì‚¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")'),
                        page.locator('p:has-text("íšŒì‚¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")'),
                        page.locator('p:has-text("ë°ì´í„° ì—†ìŒ")'),
                        page.locator('p:has-text("âŒ")'),
                        page.locator('p:has-text("ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")'),
                        page.locator('p:has-text("íšŒì‚¬ëª…ì„ ì…ë ¥í•´ì£¼ì„¸ìš”")'),
                        page.locator('p:has-text("ê¸°ì¤€ ì—°ì›”ì„ ì…ë ¥í•´ì£¼ì„¸ìš”")')
                    ]
                    
                    # ëª¨ë“  ì§€í‘œë¥¼ í•˜ë‚˜ë¡œ í•©ì¹¨
                    combined_locator = success_indicators[0]
                    for loc in success_indicators[1:] + error_indicators:
                        combined_locator = combined_locator.or_(loc)
                    
                    # .first ë¥¼ ì‚¬ìš©í•˜ì—¬ ìµœì†Œ í•˜ë‚˜ë¼ë„ ë³´ì´ë©´ ì¦‰ì‹œ ë‹¤ìŒ ë‹¨ê³„ë¡œ ì§„í–‰
                    combined_locator.first.wait_for(state="visible", timeout=120000)
                    
                    # ì„±ê³µ ì—¬ë¶€ ìµœì¢… íŒì •
                    is_success = any(loc.is_visible() for loc in success_indicators)
                    
                    if is_success:
                        print(f"  - [Success] Successfully processed {name}", flush=True)
                    else:
                        # ì—ëŸ¬ ë©”ì‹œì§€ ì¶”ì¶œ ì‹œë„
                        error_msg = "Unknown Error"
                        for loc in error_indicators:
                            if loc.is_visible():
                                error_msg = loc.inner_text().strip()
                                break
                        print(f"  - [Warning] Data not found or error reported by app for {name}: {error_msg}", flush=True)
                        update_status_to_not_found(code, name)
                except Exception as e:
                    print(f"  - [Timeout/Error] Results did not appear within 120s for {name}. Error: {e}", flush=True)
                    update_status_to_not_found(code, name)
                
                # ì„œë²„ ë¶€í•˜ ë°©ì§€ë¥¼ ìœ„í•´ ì ì‹œ ëŒ€ê¸°
                print("  - Cooling down for 5 seconds...", flush=True)
                time.sleep(5)
                
            except Exception as e:
                print(f"  - [Critical Error] Global failure for {name}: {e}", flush=True)
                update_status_to_not_found(code, name)

        print("\n[Playwright] Closing browser...", flush=True)
        browser.close()
    print("--- Automation Task Finished ---", flush=True)

if __name__ == "__main__":
    print("--- Script Entry Point ---", flush=True)
    if not MD_TOKEN:
        print("MOTHERDUCK_TOKEN is not set.", flush=True)
    else:
        run_automation()
